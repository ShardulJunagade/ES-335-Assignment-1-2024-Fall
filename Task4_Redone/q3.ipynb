{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity Labels Dictionary:  {'WALKING': 1, 'WALKING_UPSTAIRS': 2, 'WALKING_DOWNSTAIRS': 3, 'SITTING': 4, 'STANDING': 5, 'LAYING': 6}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from langchain_groq import ChatGroq\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Define the model mapping\n",
    "groq_models = {\n",
    "    \"llama3-70b\": \"llama3-70b-8192\",\n",
    "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
    "    \"gemma-7b\": \"gemma-7b-it\",\n",
    "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
    "    \"llama3-8b\": \"llama3-8b-8192\",\n",
    "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
    "    \"gemma-9b\": \"gemma2-9b-it\"\n",
    "}\n",
    "\n",
    "activity_labels = {\n",
    "    1: \"WALKING\",\n",
    "    2: \"WALKING_UPSTAIRS\",\n",
    "    3: \"WALKING_DOWNSTAIRS\",\n",
    "    4: \"SITTING\",\n",
    "    5: \"STANDING\",\n",
    "    6: \"LAYING\"\n",
    "}\n",
    "reverse_activity_labels = {v: k for k, v in activity_labels.items()}\n",
    "\n",
    "print(\"Activity Labels Dictionary: \", reverse_activity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train UCI shape:  (126, 1500)\n",
      "X_test UCI shape:  (54, 1500)\n",
      "y_train UCI shape:  (126,)\n",
      "y_test UCI shape:  (54,)\n",
      "(18, 500, 3)\n",
      "(6, 500, 3)\n",
      "y_train: (18,)\n",
      "y_test: (6,)\n",
      "x_train: (18, 1500)\n",
      "x_test: (6, 1500)\n",
      "x_train: (18, 600)\n",
      "x_test: (6, 600)\n"
     ]
    }
   ],
   "source": [
    "X_train_UCI = np.load('../FinalDataset/X_train.npy')\n",
    "X_test_UCI = np.load('../FinalDataset/X_test.npy')\n",
    "y_train_UCI = np.load('../FinalDataset/y_train.npy')\n",
    "y_test_UCI = np.load('../FinalDataset/y_test.npy')\n",
    "\n",
    "X_train_UCI =np.hstack((X_train_UCI[:,:,0],X_train_UCI[:,:,1],X_train_UCI[:,:,2]))\n",
    "X_test_UCI =np.hstack((X_test_UCI[:,:,0],X_test_UCI[:,:,1],X_test_UCI[:,:,2]))\n",
    "\n",
    "print(\"X_train UCI shape: \", X_train_UCI.shape)\n",
    "print(\"X_test UCI shape: \", X_test_UCI.shape)\n",
    "print(\"y_train UCI shape: \", y_train_UCI.shape)\n",
    "print(\"y_test UCI shape: \", y_test_UCI.shape)\n",
    "\n",
    "# Loading Data Collected in the wild\n",
    "X_train = np.load('../Our_Saved/X_train.npy')\n",
    "X_test = np.load('../Our_Saved/X_test.npy')\n",
    "y_train = np.load('../Our_Saved/y_train.npy')\n",
    "y_test = np.load('../Our_Saved/y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "X_train=np.hstack((X_train[:,:,0],X_train[:,:,1],X_train[:,:,2]))\n",
    "X_test=np.hstack((X_test[:,:,0],X_test[:,:,1],X_test[:,:,2]))\n",
    "\n",
    "print(f\"x_train: {X_train.shape}\")\n",
    "print(f\"x_test: {X_test.shape}\")\n",
    "\n",
    "\n",
    "X_train = X_train[:,:600]\n",
    "X_test = X_test[:,:600]\n",
    "\n",
    "\n",
    "print(f\"x_train: {X_train.shape}\")\n",
    "print(f\"x_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make API calls with retry logic for rate limit errors\n",
    "def make_api_call(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Rate limit error: {e}. Retrying in 10 seconds...\")\n",
    "            time.sleep(10)\n",
    "\n",
    "# Set up Groq API credentials and model\n",
    "Groq_Token = \"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\"\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select even samples for few-shot learning examples\n",
    "# samples_per_activity = 2\n",
    "# few_shot_indices = []\n",
    "# activity_count = {i: 0 for i in range(1, 7)}\n",
    "\n",
    "# for i, label in enumerate(y_train_UCI):\n",
    "#     if activity_count[label] < samples_per_activity:\n",
    "#         few_shot_indices.append(i)\n",
    "#         activity_count[label] += 1\n",
    "#     if all(count == samples_per_activity for count in activity_count.values()):\n",
    "#         break\n",
    "\n",
    "# # Create few-shot examples\n",
    "# few_shot_examples = [\n",
    "#     {\"input\": X_train_UCI[i].tolist(), \"label\": y_train_UCI[i]} for i in few_shot_indices\n",
    "# ]\n",
    "\n",
    "# # Function to create a few-shot learning prompt\n",
    "# def create_few_shot_prompt(examples, query_input):\n",
    "#     description = '''\n",
    "#         You are a highly trained human activity classification model.\n",
    "#         Each input is a 1x1500 vector containing numerical values that represent transformed features.\n",
    "#         Your task is to classify the input vector into one of the following categories:\n",
    "#         - 1: WALKING\n",
    "#         - 2: WALKING_UPSTAIRS\n",
    "#         - 3: WALKING_DOWNSTAIRS\n",
    "#         - 4: SITTING \n",
    "#         - 5: STANDING\n",
    "#         - 6: LAYING\n",
    "\n",
    "#         Here are a few examples:\\n\n",
    "#     '''\n",
    "#     prompt = description\n",
    "#     for ex in examples:\n",
    "#         example_input = \",\".join(map(str, ex['input']))\n",
    "#         prompt += f\"Input: [{example_input}]\\nLabel: {ex['label']}\\n\\n\" \n",
    "        \n",
    "#     query_input_str = \",\".join(map(str, query_input))\n",
    "#     prompt += f\"Now, classify the following input vector and return ONLY the number.\\nInput: [{query_input_str}]\\nLabel: \"\n",
    "#     return prompt\n",
    "\n",
    "# # Select 1 samples from each activity for testing\n",
    "# samples_per_activity = 1\n",
    "# selected_indices = []\n",
    "# activity_count = {i: 0 for i in range(1, 7)}\n",
    "\n",
    "# for i, label in enumerate(y_test):\n",
    "#     if activity_count[label] < samples_per_activity:\n",
    "#         selected_indices.append(i)\n",
    "#         activity_count[label] += 1\n",
    "#     if all(count == samples_per_activity for count in activity_count.values()):\n",
    "#         break\n",
    "\n",
    "# # Store predictions and true labels\n",
    "# predictions = []\n",
    "# true_labels = []\n",
    "\n",
    "# # Test the selected cases\n",
    "# for idx in selected_indices:\n",
    "#     query_input = X_test[idx].tolist()\n",
    "#     true_label = y_test[idx]\n",
    "#     prompt = create_few_shot_prompt(few_shot_examples, query_input)\n",
    "    \n",
    "#     # Make the API call and store the prediction\n",
    "#     answer = make_api_call(prompt)\n",
    "#     predicted_label = int(answer.content.strip())\n",
    "#     predictions.append(predicted_label)\n",
    "#     true_labels.append(true_label)\n",
    "    \n",
    "#     # Print the predicted and true labels\n",
    "#     print(f\"Test Case {idx + 1} ({activity_labels[true_label]}):\")\n",
    "#     print(f\"Predicted label: {predicted_label}\")\n",
    "#     print(f\"True label: {true_label}\")\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "# # Calculate and print accuracy\n",
    "# accuracy = accuracy_score(true_labels, predictions)\n",
    "# print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# # Calculate and plot the confusion matrix\n",
    "# conf_matrix = confusion_matrix(true_labels, predictions, labels=[1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "#             xticklabels=['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING'], \n",
    "#             yticklabels=['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING'])\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1 (LAYING):\n",
      "Predicted label: 4\n",
      "True label: 6\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Select even samples for few-shot learning examples\n",
    "samples_per_activity = 2\n",
    "few_shot_indices = []\n",
    "activity_count = {i: 0 for i in range(1, 7)}\n",
    "\n",
    "for i, label in enumerate(y_train_UCI):\n",
    "    if activity_count[label] < samples_per_activity:\n",
    "        few_shot_indices.append(i)\n",
    "        activity_count[label] += 1\n",
    "    if all(count == samples_per_activity for count in activity_count.values()):\n",
    "        break\n",
    "\n",
    "# Create few-shot examples\n",
    "few_shot_examples = [\n",
    "    {\"input\": X_train_UCI[i].tolist(), \"label\": y_train_UCI[i]} for i in few_shot_indices\n",
    "]\n",
    "\n",
    "# Function to create a few-shot learning prompt\n",
    "def create_few_shot_prompt(examples, query_input):\n",
    "    description = '''\n",
    "        You are a highly trained human activity classification model.\n",
    "        Each input is a 1x600 vector containing numerical values that represent transformed features.\n",
    "        Your task is to classify the input vector into one of the following categories:\n",
    "        - 1: WALKING\n",
    "        - 2: WALKING_UPSTAIRS\n",
    "        - 3: WALKING_DOWNSTAIRS\n",
    "        - 4: SITTING \n",
    "        - 5: STANDING\n",
    "        - 6: LAYING\n",
    "\n",
    "        Here are a few examples:\\n\n",
    "    '''\n",
    "    prompt = description\n",
    "    for ex in examples:\n",
    "        example_input = \",\".join(map(str, ex['input']))\n",
    "        prompt += f\"Input: [{example_input}]\\nLabel: {ex['label']}\\n\\n\" \n",
    "        \n",
    "    query_input_str = \",\".join(map(str, query_input))\n",
    "    prompt += f\"Now, classify the following input vector and return ONLY the number.\\nInput: [{query_input_str}]\\nLabel: \"\n",
    "    return prompt\n",
    "\n",
    "# Select 1 samples from each activity for testing\n",
    "samples_per_activity = 2\n",
    "selected_indices = []\n",
    "activity_count = {i: 0 for i in range(1, 7)}\n",
    "\n",
    "for i, label in enumerate(y_train):\n",
    "    if activity_count[label] < samples_per_activity:\n",
    "        selected_indices.append(i)\n",
    "        activity_count[label] += 1\n",
    "    if all(count == samples_per_activity for count in activity_count.values()):\n",
    "        break\n",
    "\n",
    "# Store predictions and true labels\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Test the selected cases\n",
    "for idx in selected_indices:\n",
    "    query_input = X_train[idx].tolist()\n",
    "    true_label = y_train[idx]\n",
    "    prompt = create_few_shot_prompt(few_shot_examples, query_input)\n",
    "    \n",
    "    # Make the API call and store the prediction\n",
    "    answer = make_api_call(prompt)\n",
    "    predicted_label = int(answer.content.strip())\n",
    "    predictions.append(predicted_label)\n",
    "    true_labels.append(true_label)\n",
    "    \n",
    "    # Print the predicted and true labels\n",
    "    print(f\"Test Case {idx + 1} ({activity_labels[true_label]}):\")\n",
    "    print(f\"Predicted label: {predicted_label}\")\n",
    "    print(f\"True label: {true_label}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate and plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions, labels=[1, 2, 3, 4, 5, 6])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING'], \n",
    "            yticklabels=['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
